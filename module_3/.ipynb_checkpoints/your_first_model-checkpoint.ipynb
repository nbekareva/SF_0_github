{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка Pandas и очистка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "# from collections import Counter\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('main_task.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant_id</th>\n",
       "      <th>City</th>\n",
       "      <th>Cuisine Style</th>\n",
       "      <th>Ranking</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Price Range</th>\n",
       "      <th>Number of Reviews</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>URL_TA</th>\n",
       "      <th>ID_TA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26603</th>\n",
       "      <td>id_651</td>\n",
       "      <td>Lyon</td>\n",
       "      <td>['French']</td>\n",
       "      <td>652.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>$$ - $$$</td>\n",
       "      <td>61.0</td>\n",
       "      <td>[['Great wine and platter. Friendly staff', 'M...</td>\n",
       "      <td>/Restaurant_Review-g187265-d2718480-Reviews-Le...</td>\n",
       "      <td>d2718480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12752</th>\n",
       "      <td>id_222</td>\n",
       "      <td>Madrid</td>\n",
       "      <td>['Mediterranean', 'European', 'Spanish', 'Vege...</td>\n",
       "      <td>223.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>$$ - $$$</td>\n",
       "      <td>128.0</td>\n",
       "      <td>[['Best Jamon Iberico we had in Spain', 'Madri...</td>\n",
       "      <td>/Restaurant_Review-g187514-d11938372-Reviews-E...</td>\n",
       "      <td>d11938372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24855</th>\n",
       "      <td>id_13763</td>\n",
       "      <td>London</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13773.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>[['When in Petticoat Lane', 'Good coffee frien...</td>\n",
       "      <td>/Restaurant_Review-g186338-d5567535-Reviews-Ca...</td>\n",
       "      <td>d5567535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12360</th>\n",
       "      <td>id_13684</td>\n",
       "      <td>Paris</td>\n",
       "      <td>['Italian']</td>\n",
       "      <td>13686.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[['Very good food'], ['09/27/2017']]</td>\n",
       "      <td>/Restaurant_Review-g187147-d12571253-Reviews-M...</td>\n",
       "      <td>d12571253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25991</th>\n",
       "      <td>id_8071</td>\n",
       "      <td>Madrid</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8078.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>[[], []]</td>\n",
       "      <td>/Restaurant_Review-g187514-d1599930-Reviews-Ca...</td>\n",
       "      <td>d1599930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Restaurant_id    City  \\\n",
       "26603        id_651    Lyon   \n",
       "12752        id_222  Madrid   \n",
       "24855      id_13763  London   \n",
       "12360      id_13684   Paris   \n",
       "25991       id_8071  Madrid   \n",
       "\n",
       "                                           Cuisine Style  Ranking  Rating  \\\n",
       "26603                                         ['French']    652.0     4.0   \n",
       "12752  ['Mediterranean', 'European', 'Spanish', 'Vege...    223.0     4.5   \n",
       "24855                                                NaN  13773.0     4.5   \n",
       "12360                                        ['Italian']  13686.0     5.0   \n",
       "25991                                                NaN   8078.0     3.0   \n",
       "\n",
       "      Price Range  Number of Reviews  \\\n",
       "26603    $$ - $$$               61.0   \n",
       "12752    $$ - $$$              128.0   \n",
       "24855         NaN                8.0   \n",
       "12360         NaN                2.0   \n",
       "25991         NaN               21.0   \n",
       "\n",
       "                                                 Reviews  \\\n",
       "26603  [['Great wine and platter. Friendly staff', 'M...   \n",
       "12752  [['Best Jamon Iberico we had in Spain', 'Madri...   \n",
       "24855  [['When in Petticoat Lane', 'Good coffee frien...   \n",
       "12360               [['Very good food'], ['09/27/2017']]   \n",
       "25991                                           [[], []]   \n",
       "\n",
       "                                                  URL_TA      ID_TA  \n",
       "26603  /Restaurant_Review-g187265-d2718480-Reviews-Le...   d2718480  \n",
       "12752  /Restaurant_Review-g187514-d11938372-Reviews-E...  d11938372  \n",
       "24855  /Restaurant_Review-g186338-d5567535-Reviews-Ca...   d5567535  \n",
       "12360  /Restaurant_Review-g187147-d12571253-Reviews-M...  d12571253  \n",
       "25991  /Restaurant_Review-g187514-d1599930-Reviews-Ca...   d1599930  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первоначальная версия датасета состоит из десяти столбцов, содержащих следующую информацию:\n",
    "\n",
    "* Restaurant_id — идентификационный номер ресторана / сети ресторанов;\n",
    "* City — город, в котором находится ресторан;\n",
    "* Cuisine Style — кухня или кухни, к которым можно отнести блюда, предлагаемые в ресторане;\n",
    "* Ranking — место, которое занимает данный ресторан среди всех ресторанов своего города;\n",
    "* Rating — рейтинг ресторана по данным TripAdvisor (именно это значение должна будет предсказывать модель);\n",
    "* Price Range — диапазон цен в ресторане;\n",
    "* Number of Reviews — количество отзывов о ресторане;\n",
    "* Reviews — данные о двух отзывах, которые отображаются на сайте ресторана;\n",
    "* URL_TA — URL страницы ресторана на TripAdvosor;\n",
    "* ID_TA — идентификатор ресторана в базе данных TripAdvisor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код по очистке данных и генерации новых признаков\n",
    "# При необходимости добавьте ячейки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.duplicated()]   # проверяем, есть ли дубли в данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задания из модуля"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1\n",
    "df['Price Range'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2\n",
    "df['City'].value_counts().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.3\n",
    "print(df['Cuisine Style'].value_counts())\n",
    "print(type(df['Cuisine Style'][0]))\n",
    "\n",
    "pat = re.compile('\\'(.*?)\\'')\n",
    "# cuisine_styles = df['Cuisine Style'].apply(lambda x: ['default'] if pd.isnull(x) else pat.findall(x))\n",
    "cuisine_styles = df['Cuisine Style'].dropna().apply(lambda x: pat.findall(x))\n",
    "cuisine_styles.explode().value_counts(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.4\n",
    "def replacer(matches):\n",
    "    \"\"\"\n",
    "    Defines how re.sub should format a string including special cases.\n",
    "    \"\"\"\n",
    "    \n",
    "#     След фиксы пока в виде костылей, возм исправлю позже\n",
    "    text = re.sub('\\\\\\\\x7f', '', matches.group('texts'))   # удаляем один бинарный символ (срока ...)\n",
    "    text = re.sub('\\\\\\\\', '', text)   # удаляем одиночный \\ в слове \"can\\'t\" (строка ...)\n",
    "    text = re.sub('\\sna', \" 'nan\", text)   # для строки 5315, содержащей nan\n",
    "    text = re.sub('an,\\s', \"nan', \", text)   # то же для строки 22958, содержащей nan в начале\n",
    "    \n",
    "    text = re.sub('\"', \"'\", text)   # для всех цитат и апострофов в отзывах заменяем \" на ', тк json.loads не работает с \"\n",
    "    texts = re.sub('((\\'|\\\"), (\\'|\\\"))', '\", \"', text)\n",
    "    dates = re.sub('((\\'|\\\"), (\\'|\\\"))', '\", \"', matches.group('dates'))\n",
    "    \n",
    "    return '[[\"' + texts + '\"], [\"' + dates + '\"]]'\n",
    "\n",
    "\n",
    "def parse_review(string, obj):\n",
    "    \"\"\"\n",
    "    Converts strings of df['Reviews'] into json.loads digestiable format.\n",
    "    \"\"\"\n",
    "    \n",
    "    string = re.sub('(\\[\\[.)(?P<texts>.*?)(.\\], \\[.)(?P<dates>.*?)(.\\]\\])', replacer, string)\n",
    "    lst = json.loads(string)   # парсим\n",
    "\n",
    "    if obj == 'Reviews':\n",
    "        return lst[0] or None\n",
    "    else:\n",
    "        return lst[1] or None\n",
    "\n",
    "\n",
    "def compare_lengths(row):\n",
    "    \"\"\"\n",
    "    Checks if parsed lists of according reviews and dates are of the same length.\n",
    "    \"\"\"\n",
    "    \n",
    "    if row['Review'] is not None:\n",
    "        if len(row['Review']) != len(row['Review date']):\n",
    "            display(row)\n",
    "            print(len(row['Review']), len(row['Review date']))\n",
    "\n",
    "\n",
    "reviews_df = pd.DataFrame(columns=['Review', 'Review date'])\n",
    "reviews_df['Review'] = df['Reviews'].apply(parse_review, obj='Reviews')\n",
    "reviews_df['Review date'] = df['Reviews'].apply(parse_review, obj='Dates')\n",
    "display(reviews_df)\n",
    "\n",
    "reviews_df.apply(compare_lengths, axis=1)\n",
    "reviews_df = reviews_df.apply(pd.Series.explode)#.reset_index()\n",
    "reviews_df['Review date'] = pd.to_datetime(reviews_df['Review date'])\n",
    "display(reviews_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# строки, на которых спотыкалось:\n",
    "stumble1 = str([[\"Don't eat here if you have a train to catc...\", 'Lunchtime drink'], ['10/11/2017', '07/03/2017']])\n",
    "stumble2 = str([['\"Best Local\"', 'Perfect pitstop'], ['02/09/2017', '04/17/2015']])\n",
    "stumble3 = str([['Lillian restaurant reviews', 'Greasy Spoon\\x7f'], ['12/20/2017', '07/09/2017']])\n",
    "stumble4 = str([['Sat night', 'Can\\'t even explain.. \"A\" place.. A \"100...'], ['10/22/2017', '05/11/2017']])\n",
    "stumble5 = df.iloc[5315]['Reviews']   # 5315\n",
    "stumble6 = df.iloc[22958]['Reviews']   # 22958\n",
    "\n",
    "\n",
    "def replacer1(matches):\n",
    "    text = re.sub('\\\\\\\\x7f', '', matches.group('texts'))   # удаляем один бинарный символ (срока ...)\n",
    "    text = re.sub('\\\\\\\\', '', text)   # удаляем одиночный \\ в слове \"can\\'t\" (строка ...)\n",
    "    text = re.sub('\\sna', \" 'nan\", text)   # для строки 5315, содержащей nan в конце\n",
    "    text = re.sub('an,\\s', \"nan', \", text)   # то же для строки 22958, содержащей nan в начале\n",
    "    text = re.sub('\"', \"'\", text)   # для всех цитат и апострофов в отзывах заменяем \" на ', тк json.loads не работает с \"\n",
    "    texts = re.sub('((\\'|\\\"), (\\'|\\\"))', '\", \"', text)\n",
    "    dates = re.sub('((\\'|\\\"), (\\'|\\\"))', '\", \"', matches.group('dates'))\n",
    "    return '[[\"' + texts + '\"], [\"' + dates + '\"]]'\n",
    "\n",
    "\n",
    "# stumble3.encode('utf-8').replace(b'\\x7f', '')\n",
    "print(stumble3)\n",
    "print(stumble3.replace(r'\\x7f', ''))\n",
    "print(stumble4.replace('\\\\', '\\\\\\\\'))\n",
    "\n",
    "stumble5 = re.sub('(\\[\\[.)(?P<texts>.*?)(.\\], \\[.)(?P<dates>.*?)(.\\]\\])', replacer1, stumble5)\n",
    "# lst1 = json.loads(stumble5)   # парсим\n",
    "print(stumble5)\n",
    "\n",
    "y = eval(stumble4)\n",
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.4\n",
    "print(reviews_df['Review date'].max())\n",
    "last = reviews_df['Review date'].max()\n",
    "first = reviews_df['Review date'].min()\n",
    "print(last, first)\n",
    "print(last - first)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В ходе выполнения заданий из модуля выяснили, что столбцы \"Cuisine Style\", \"Reviews\" заполнены строками, выглядящими как списки, превратили их в списки, проверили корректность заполнения, для \"Cuisine Style\" посчитали число уникальных значений, собрали их в массив; \"Reviews\" разбили на отзывы и их даты, поставили в соответствие. Т.о. сделана часть работы по извлечению инсайтов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Извлекаем инсайты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Сategorical parameters:</i> Restaurant_id, City, Cuisine Style, Reviews, URL_TA, ID_TA\n",
    "\n",
    "<i>Ordinal parameters:</i> Price Range\n",
    "\n",
    "<i>Numerical parameters:</i> Ranking, Rating, Number of Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Restaurant_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total input number: {}'.format(len(df['Restaurant_id'])))\n",
    "print('Total amount of restaurants: {}'.format(df['Restaurant_id'].nunique()))\n",
    "print('Most comon restaurants (over 10 inputs): ')\n",
    "common_rests = df['Restaurant_id'].value_counts()\n",
    "common_rests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if restaurants with the same id are located in one city (or it's the same restaurant)\n",
    "for rest in common_rests.index:\n",
    "#     print('Rest {}, number of inputs: {}, number of cities: {}'.format(rest,     # вывод слишком длинный, поэтому см ниже\n",
    "#             common_rests[rest], df[df['Restaurant_id'] == rest]['City'].nunique()))\n",
    "    if common_rests[rest] != df[df['Restaurant_id'] == rest]['City'].nunique():\n",
    "        print('inequal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:** один и тот же ресторан в разных городах выступает под одним id (возможно, сети). Записи о ресторанах не повторяются, пропусков нет."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. City"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['City'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Города указаны должным образом, пропусков нет, необходимо сгенерировать dummy-переменные."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Cuisine Style\n",
    "\n",
    "Cм задание 4.3.\n",
    "\n",
    "В этой колонке содержатся строки, визуально выглядящие как списки. Есть пропуски, попытаемся заполнить их ниже."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Reviews\n",
    "\n",
    "См. задание 4.4.\n",
    "\n",
    "Также строки, выглядящие как списки, каждая содержит 2 \"списка\" - первый с отзывами, второй с их датами, по 0-2 отзыва в каждой ячейке. Разделим их и вынесем в отдельные колонки.\n",
    "\n",
    "Есть как настоящие пропуски, так и пустые списки. Поэтому после извлечения настоящих отзывов получится немало пропусков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Reviews'][1], '\\n', type(df['Reviews'][0]))\n",
    "print(df['Reviews'][0])\n",
    "print('Кол-во пропусков: {}'.format(df['Reviews'].isna().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Reviews_new'] = df['Reviews'].apply(parse_review, obj='Reviews')\n",
    "df['Review_dates'] = df['Reviews'].apply(parse_review, obj='Dates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_item(cell):\n",
    "    if cell and i < len(cell):\n",
    "        return cell[i]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "for i in range(2):\n",
    "    col_name = 'Review ' + str(i + 1)\n",
    "    df[col_name] = df['Reviews_new'].apply(extract_item)\n",
    "    \n",
    "    col_name_date = 'Date ' + str(i + 1)\n",
    "    df[col_name_date] = pd.to_datetime(df['Review_dates'].apply(extract_item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# насколько полно заполнены отзывы и их даты:\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Reviews', 'Reviews_new', 'Review_dates'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. URL_TA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['URL_TA'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Число уникальных записей на 20 меньше, чем общее число записей. Посмотрим на повторяющиеся."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['URL_TA'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что в ссылке на ресторан на TripAdvisor \"зашиты\" названия и местонахождения (геолокации) ресторанов, а также какие-то численные данные с префиксами d и g. Эти признаки можно из ссылок извлечь, интерпретировать и использовать в дальнейшем. Например, по названию ресторана можно попробовать определить кухню, которую в нем предлагают. Геолокация вряд ли понадобится, т.к. колонка City у нас не содержит пропусков.\n",
    "\n",
    "Можно проверить, совпадают ли города в колонке City с городами в ссылке.\n",
    "\n",
    "Извлекаем признаки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pat(cell):\n",
    "    match = pat.search(cell)\n",
    "    return match.group(feature) if match else None\n",
    "\n",
    "\n",
    "pat = re.compile('(?P<URL_g>g.*)-(?P<URL_d>d.+)-Reviews-(?P<Restaurant_title>.*)-(?P<Restaurant_geo>.*)\\.')\n",
    "re_groups = ['URL_g', 'URL_d', 'Restaurant_title', 'Restaurant_geo']\n",
    "\n",
    "\n",
    "for feature in re_groups:\n",
    "    df[feature] = df['URL_TA'].apply(find_pat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# проверим те строки, где не был найден паттерн (regex не сработал):\n",
    "subset = df[df['URL_g'].isna()]\n",
    "display(subset)\n",
    "for i in subset['URL_TA']:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# воспользуемся отдельным паттерном для этих строк:\n",
    "inds = subset.index\n",
    "\n",
    "pat1 = re.compile('(?P<URL_g>g.*)-(?P<URL_d>d.+)-Reviews-(?P<Restaurant_geo>.*)\\.')\n",
    "re_groups1 = ['URL_g', 'URL_d', 'Restaurant_geo']\n",
    "\n",
    "for feature in re_groups1:\n",
    "    df[feature][inds] = df['URL_TA'][inds].apply(lambda x: pat1.search(x).group(feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверим, все ли заполнилось:\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь посмотрим, совпадают ли города в колонке City с городами, извлеченными из ссылок на рестораны в TripAdvisor. Заодно возьмем на рассмотрение те рестораны, где кухни отсутствовали:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Cuisine Style'].isna()].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Гео, извлеченное из URL, содержит более развернутую информацию о местонахождении ресторана (район города, муниципальный округ и т.д.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. URL_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['URL_g'].nunique())\n",
    "df['URL_g'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[df['URL_g'] == 'g186338'].shape)\n",
    "df[df['URL_g'] == 'g186338'].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скорее всего, этот признак соответствует геолокации ресторана, т.е. совпадает с 'Restaurant geo' (не с 'City' - ранее видели, что всего городов 31, т.е. меньше, чем никальных значений 'URL_g')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Restaurant_geo'].nunique())\n",
    "df['Restaurant_geo'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не совсем - цифры различаются. Далее углубляться не будем, все равно колонка с городами не содержит пропусков - использовать URL_g незачем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. URL_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['URL_d'].nunique())\n",
    "df['URL_d'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этот признак дублирует ID_TA (id ресторана на TripAdvisor-e) - см. ниже."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. ID_TA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ID_TA'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "v_c = df['ID_TA'].value_counts()\n",
    "v_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Опять число уникальных записей на 20 меньше, чем общее число записей - как в URL_TA. Скорее всего, повторения этих признаков перекрываются. Посмотрим, что общего у записей с одинаковым ID_TA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rep_id_ta = v_c[v_c > 1].index\n",
    "id_ta_subset = df[df['ID_TA'].isin(rep_id_ta)].sort_values('ID_TA')\n",
    "display(id_ta_subset)\n",
    "print('N of lines: {}'.format(id_ta_subset.shape[0]))\n",
    "\n",
    "for col in id_ta_subset.columns:\n",
    "    print('N unique in col {}: {}'.format(col, id_ta_subset[col].nunique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все признаки одинаковы у пар ресторанов за исключением id, Ranking - они уникальны, однако очень близки. Возможно, произошел какой-то сбой и были внесены записи об одних и тех же ресторанах, только с небольшой разницей во времени."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# подумать, как можно заполнить пропуски в этой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordinal parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Price Range'].isna().sum())\n",
    "df['Price Range'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Колонка заполнена корректно, можно заменить на численные эквиваленты значений (см ниже в feature engineering).\n",
    "\n",
    "Имеются пропуски, ниже попытаемся заполнить на основе связей с другими признаками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Ranking', 'Rating']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[['Ranking', 'Rating']].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.boxplot(data=df[['Ranking', 'Rating']], hue=df[['Ranking', 'Rating']].columns)\n",
    "sns.boxplot(data=df['Ranking'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Заполнение пропусков\n",
    "\n",
    "Т.о. пропуски содержатся в колонках **'Cuisine Style', 'Price Range', 'Number of Reviews', 'Review n', 'Date n', 'Restaurant title'**.\n",
    "\n",
    "1. **'Cuisine Style', 'Price Range', 'Number of Reviews'** можно попробовать заполнить на основе предполагаемых связей с другими признаками:\n",
    "\n",
    "-- 'Cuisine Style': ресторан может принадлежать к сети, в сетевых ресторанах, как правило, подают одну и ту же кухню - проверить можно по названию 'Restaurant_title';\n",
    "\n",
    "-- название ресторана 'Restaurant_title' может содержать или подразумевать кухню, которую в нем подают, например, ресторан с японским названием, расположенный в Италии, скорее всего предлагает японскую кухню;\n",
    "\n",
    "-- 'Price Range' может также зависеть от принадлежности ресторана к сети;\n",
    "\n",
    "-- его можно заполнить на основе распределения цен в ресторанах в каждом отдельном городе / подающих одну кухню / имеющих близкое число отзывов - в общем или в каждом отдельном городе / близкий 'Ranking'/'Rating' аналогично. Для этого скорее всего нужно формулировать гипотезы и статистически их проверять, затем заполнять пропуски на основе подтвержденных.\n",
    "\n",
    "-- 'Number of Reviews' - на основе его корреляции с 'Ranking' в каждом отдельном городе.\n",
    "\n",
    "2. **'Review n', 'Date n', 'Restaurant title'** заполнить невозможно.\n",
    "\n",
    "<br>\n",
    "<i>А можно не строить гипотез и спарсить данные прямо с сайта. Так и сделаем.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant_id</th>\n",
       "      <th>Cuisine Style</th>\n",
       "      <th>Price Range</th>\n",
       "      <th>Number of Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>id_2791</td>\n",
       "      <td>['Chinese', 'Asian']</td>\n",
       "      <td>$$ - $$$</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>id_1327</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>id_4637</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>id_2434</td>\n",
       "      <td>['Vietnamese']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>id_5209</td>\n",
       "      <td>['Chinese', 'Japanese', 'Seafood']</td>\n",
       "      <td>$$ - $$$</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9962</th>\n",
       "      <td>id_1540</td>\n",
       "      <td>['Bar', 'European']</td>\n",
       "      <td>$$ - $$$</td>\n",
       "      <td>253.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9973</th>\n",
       "      <td>id_6048</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9970</th>\n",
       "      <td>id_760</td>\n",
       "      <td>['Bar', 'European', 'Czech']</td>\n",
       "      <td>$</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9952</th>\n",
       "      <td>id_2268</td>\n",
       "      <td>['Asian', 'Thai', 'Vegetarian Friendly']</td>\n",
       "      <td>$</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9936</th>\n",
       "      <td>id_2470</td>\n",
       "      <td>['Mediterranean', 'European', 'Spanish']</td>\n",
       "      <td>$$ - $$$</td>\n",
       "      <td>106.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9887 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Restaurant_id                             Cuisine Style Price Range  \\\n",
       "19         id_2791                      ['Chinese', 'Asian']    $$ - $$$   \n",
       "32         id_1327                                       NaN         NaN   \n",
       "13         id_4637                                       NaN           $   \n",
       "33         id_2434                            ['Vietnamese']         NaN   \n",
       "37         id_5209        ['Chinese', 'Japanese', 'Seafood']    $$ - $$$   \n",
       "...            ...                                       ...         ...   \n",
       "9962       id_1540                       ['Bar', 'European']    $$ - $$$   \n",
       "9973       id_6048                                       NaN         NaN   \n",
       "9970        id_760              ['Bar', 'European', 'Czech']           $   \n",
       "9952       id_2268  ['Asian', 'Thai', 'Vegetarian Friendly']           $   \n",
       "9936       id_2470  ['Mediterranean', 'European', 'Spanish']    $$ - $$$   \n",
       "\n",
       "      Number of Reviews  \n",
       "19                 18.0  \n",
       "32                  1.0  \n",
       "13                 11.0  \n",
       "33                  4.0  \n",
       "37                 74.0  \n",
       "...                 ...  \n",
       "9962              253.0  \n",
       "9973                NaN  \n",
       "9970               80.0  \n",
       "9952               23.0  \n",
       "9936              106.0  \n",
       "\n",
       "[9887 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_parsed0 = pd.read_csv('parsed_data_output0.csv', index_col=0)\n",
    "df_parsed0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9887 entries, 19 to 9936\n",
      "Data columns (total 4 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Restaurant_id      9887 non-null   object \n",
      " 1   Cuisine Style      7894 non-null   object \n",
      " 2   Price Range        7337 non-null   object \n",
      " 3   Number of Reviews  8862 non-null   float64\n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 706.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_parsed0.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40000 entries, 0 to 39999\n",
      "Data columns (total 10 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Restaurant_id      40000 non-null  object \n",
      " 1   City               40000 non-null  object \n",
      " 2   Cuisine Style      30717 non-null  object \n",
      " 3   Ranking            40000 non-null  float64\n",
      " 4   Rating             40000 non-null  float64\n",
      " 5   Price Range        26114 non-null  object \n",
      " 6   Number of Reviews  37457 non-null  float64\n",
      " 7   Reviews            40000 non-null  object \n",
      " 8   URL_TA             40000 non-null  object \n",
      " 9   ID_TA              40000 non-null  object \n",
      "dtypes: float64(3), object(7)\n",
      "memory usage: 3.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5946"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_parsed0['Restaurant_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5988"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:10000]['Restaurant_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Incompatible indexer with Series",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-8e148f0cc276>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Cuisine Style'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mrest_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Restaurant_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Cuisine Style'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_parsed0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_parsed0\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Restaurant_id'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mrest_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Cuisine Style'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Programs\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    668\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m         \u001b[0miloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"iloc\"\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 670\u001b[1;33m         \u001b[0miloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    671\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_validate_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[1;34m(self, indexer, value)\u001b[0m\n\u001b[0;32m   1640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1641\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1642\u001b[1;33m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_align_series\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1643\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1644\u001b[0m             \u001b[0minfo_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minfo_axis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_align_series\u001b[1;34m(self, indexer, ser, multiindex_indexer)\u001b[0m\n\u001b[0;32m   1952\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1953\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1954\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Incompatible indexer with Series\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1955\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1956\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_align_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mABCDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Incompatible indexer with Series"
     ]
    }
   ],
   "source": [
    "for idx, row in df.dropna(axis=0, subset=['Cuisine Style']).iterrows():\n",
    "    rest_id = row['Restaurant_id']\n",
    "    df.loc[idx, 'Cuisine Style'] = df_parsed0.loc[df_parsed0['Restaurant_id'] == rest_id, 'Cuisine Style']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant_id</th>\n",
       "      <th>Cuisine Style</th>\n",
       "      <th>Price Range</th>\n",
       "      <th>Number of Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>id_2904</td>\n",
       "      <td>['Italian']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2353</th>\n",
       "      <td>id_2904</td>\n",
       "      <td>['Italian', 'Mediterranean', 'Spanish']</td>\n",
       "      <td>$</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3712</th>\n",
       "      <td>id_2904</td>\n",
       "      <td>['German', 'European', 'Vegetarian Friendly']</td>\n",
       "      <td>$$ - $$$</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4537</th>\n",
       "      <td>id_2904</td>\n",
       "      <td>['Mexican']</td>\n",
       "      <td>$</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7460</th>\n",
       "      <td>id_2904</td>\n",
       "      <td>['Chinese', 'Asian', 'Cantonese']</td>\n",
       "      <td>$$ - $$$</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Restaurant_id                                  Cuisine Style Price Range  \\\n",
       "100        id_2904                                    ['Italian']         NaN   \n",
       "2353       id_2904        ['Italian', 'Mediterranean', 'Spanish']           $   \n",
       "3712       id_2904  ['German', 'European', 'Vegetarian Friendly']    $$ - $$$   \n",
       "4537       id_2904                                    ['Mexican']           $   \n",
       "7460       id_2904              ['Chinese', 'Asian', 'Cantonese']    $$ - $$$   \n",
       "\n",
       "      Number of Reviews  \n",
       "100                 4.0  \n",
       "2353               29.0  \n",
       "3712               35.0  \n",
       "4537               32.0  \n",
       "7460               21.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "100                                       ['Italian']\n",
       "2353          ['Italian', 'Mediterranean', 'Spanish']\n",
       "3712    ['German', 'European', 'Vegetarian Friendly']\n",
       "4537                                      ['Mexican']\n",
       "7460                ['Chinese', 'Asian', 'Cantonese']\n",
       "Name: Cuisine Style, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rest_id = df.iloc[100]['Restaurant_id']\n",
    "display(df_parsed0.loc[df_parsed0['Restaurant_id'] == rest_id])\n",
    "df_parsed0.loc[df_parsed0['Restaurant_id'] == rest_id, 'Cuisine Style']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['American', 'Bar', 'European', 'Pub']\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[9962, 'Cuisine Style']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Restaurant_id                                       id_1540\n",
       "Cuisine Style        ['American', 'Bar', 'European', 'Pub']\n",
       "Price Range                                        $$ - $$$\n",
       "Number of Reviews                                       147\n",
       "Name: 9962, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[9962, ['Restaurant_id', 'Cuisine Style', 'Price Range', 'Number of Reviews']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Cuisine Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверяем, много ли пропусков. Ранее мы видели, что id ресторана не зависит от принадлежности к сети, т.е. у одинаковых\n",
    "# id могут быть совершенно разные кухни. Проверим зависимость от названия, извлеченного из url:\n",
    "print('Число пропусков в кухнях: {}'.format(df['Cuisine Style'].isna().sum()))\n",
    "print('Число уникальных названий ресторанов в строках с пропущенными кухнями: {}'.format(df[df['Cuisine Style'].isna()]\n",
    "                                                                                         ['Restaurant_title'].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Restaurant_title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(df[df['Restaurant_title'] == 'Burger_King'].shape)\n",
    "df[df['Restaurant_title'] == 'Burger_King'].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[df['Restaurant_title'] == 'Hippopotamus'].shape)\n",
    "df[df['Restaurant_title'] == 'Hippopotamus'].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Т.о. имеются сети ресторанов с пропусками в кухнях => их можно легко заполнить.\n",
    "\n",
    "NB: Стили кухонь могут немного отличаться в зависимости от геолокации. Можно заполнять в зависимости от гео, однако не будем усложнять задачу и заполним наиболее популярными значениями из выборок по названиям ресторанов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция очень долгая, необходимо оптимизировать\n",
    "# заполняем пропуски кухонь в сетевых ресторанах\n",
    "\n",
    "def fill_cuisine_na(row):\n",
    "    \"\"\"\n",
    "    Fills in missing cuisine style for chain restaurants.\n",
    "    \"\"\"\n",
    "    \n",
    "    if pd.isnull(row['Cuisine Style']):\n",
    "        title = row['Restaurant_title']\n",
    "        if title:   # проверяем, нет ли пропуска в названии ресторана, у нас имеются 2 таких строки. Если пропуск - вернется None\n",
    "            subset = df[df['Restaurant_title'] == title]['Cuisine Style']\n",
    "            if subset.nunique() > 0:                    # если наборы кухонь разные\n",
    "                return subset.value_counts().idxmax()   # возвращаем наиболее часто встречающееся значение\n",
    "    else:\n",
    "        return row['Cuisine Style']\n",
    "\n",
    "\n",
    "cuisine_styles_filled = df.apply(fill_cuisine_na, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuisine_styles_filled.isna().sum()   # сократили на ~1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сначала преобразуем строки в списки\n",
    "# pat = re.compile('\\'(.*?)\\'')\n",
    "# df['Cuisine Style'] = df['Cuisine Style'].dropna().apply(lambda x: pat.findall(x))   # regex is more efficient that eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# заполняем пропуски кухонь на основе названий ресторанов:\n",
    "\n",
    "# def cuisine_from_title(row):\n",
    "#     title = ...\n",
    "#     for word in df[]:\n",
    "        \n",
    "def split_title(title):\n",
    "    if pd.isnull(title):\n",
    "        return None\n",
    "    else:\n",
    "        splitted = title.split('_')\n",
    "        splitted = list(filter(lambda x: len(x) > 2, splitted))\n",
    "        return splitted\n",
    "\n",
    "titles_words = df[df['Cuisine Style'].notna()]['Restaurant_title'].apply(split_title)\n",
    "titles_of_na_cuisines = df[df['Cuisine Style'].isna()]['Restaurant_title'].apply(split_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "titles_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(titles_of_na_cuisines.iloc[2])\n",
    "\n",
    "cur_cuisines = []\n",
    "\n",
    "for idx, title in np.ndenumerate(df[df['Cuisine Style'].notna()]['Restaurant_title'].dropna()):\n",
    "    if any(word in title for word in titles_of_na_cuisines.iloc[2]):\n",
    "        print(title)\n",
    "        print(df.iloc[idx]['Cuisine Style'])\n",
    "        cur_cuisines.append(df.iloc[idx]['Cuisine Style'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Restaurant_title'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# на основе распределения кухонь по городам - последний и наименее точный метод:\n",
    "\n",
    "def cuisine_distr_in_city(city):\n",
    "    cuisines = df[df['Restaurant_geo'] == city]['Cuisine Style'].apply(lambda x: None if pd.isnull(x)\n",
    "                                                        else re.findall('\\'(.*?)\\'', x)).explode().value_counts()\n",
    "    print(city)\n",
    "    print(cuisines.nlargest(3))\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    sns.barplot(x=cuisines.index, y=cuisines.values, data=cuisines, ax=ax)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "na_cuisine_geos = df[df['Cuisine Style'].isna()]['Restaurant_geo'].unique()   # города, в которых есть пропуски кухонь\n",
    "# df[df['Restaurant_geo'] == cui_na_geos[0]]['Cuisine Style'].apply(lambda x: None if pd.isnull(x) else re.findall('\\'(.*?)\\'', x)).explode().value_counts().plot.bar()\n",
    "\n",
    "for city in na_cuisine_geos[:10]:\n",
    "    cuisine_distr_in_city(city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Cuisine Style'] = cuisine_styles_filled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. URL_g\n",
    "\n",
    "Из url мы извлекли геолокацию ресторанов, проверим, есть ли пустоты в городах и можно ли их заполнить с помощью нового параметра."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['URL_g'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['City'].isna()].sort_values('URL_g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Cuisine Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# pd.concat([df[['Restaurant_id']], pd.get_dummies(df.explode('Cuisine Style')['Cuisine Style'], prefix='Cuisine', dummy_na=True)], axis=1, verify_integrity=True).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# option: explode by cuisines, get dummies, drop duplicates\n",
    "\n",
    "def cuisine_dummies(rest):\n",
    "#     print(rest, type(rest))\n",
    "    if pd.isnull(rest):   # if cuisines in strings\n",
    "#     if isinstance(rest, list) is False:   # if cuisines in lists\n",
    "        return 0\n",
    "    else:\n",
    "        return int(cuisine in rest)     \n",
    "    \n",
    "    \n",
    "unique_cuisine_styles = np.sort(cuisine_styles.explode().unique())\n",
    "\n",
    "for cuisine in unique_cuisine_styles:\n",
    "    cuisine_prefixed = 'Cuisine_' + cuisine\n",
    "    df[cuisine_prefixed] = df['Cuisine Style'].apply(cuisine_dummies)\n",
    "\n",
    "df['Cuisine_nan'] = df['Cuisine Style'].apply(lambda x: 1 if pd.isnull(x) else 0)   # if cuisines in strings\n",
    "# df['Cuisine_nan'] = df['Cuisine Style'].apply(lambda x: 0 if isinstance(x, list) else 1)   # if cuisines in lists\n",
    "\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from stackoverflow:\n",
    "# https://stackoverflow.com/questions/29034928/pandas-convert-a-column-of-list-to-dummies\n",
    "# pd.get_dummies(df['Cuisine Style'].apply(pd.Series).stack(), dummy_na=True).sum(level=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. City"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df, pd.get_dummies(df['City'], prefix='City', dummy_na=True)], axis=1, verify_integrity=True)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ver 1.0\n",
    "# df['Review'] = df['Reviews'].apply(parse_review, obj='Reviews')\n",
    "# df = df.explode('Review')\n",
    "# df.loc[:, ['Review', 'Review date']] = reviews_df.loc[:, ['Review', 'Review date']]\n",
    "\n",
    "# # feature engineering\n",
    "# df['Review year'] = df['Review date'].dt.year\n",
    "# # df['Review month'] = df['Review date'].dt.month\n",
    "# # df['Review day'] = df['Review date'].dt.day\n",
    "# # df['Review day of week'] = df['Review date'].dt.dayofweek   # без них результат лучше\n",
    "# df['Review day of year'] = df['Review date'].dt.dayofyear\n",
    "\n",
    "# df.drop('Reviews', axis=1, inplace=True)\n",
    "# df.reset_index(inplace=True, drop=True)\n",
    "# df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ver 2.0:\n",
    "# найдем разницу во времени между отзывами:\n",
    "\n",
    "def get_time_gap(row):\n",
    "    return (row['Date 1'] - row['Date 2']).days if row['Date 1'] and row['Date 2'] else None\n",
    "\n",
    "\n",
    "df['Time gap'] = df.apply(get_time_gap, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# насколько стары отзывы:\n",
    "\n",
    "def review_age(cell):\n",
    "    return (now - cell).days if cell else None\n",
    "\n",
    "\n",
    "now = datetime.now()\n",
    "df['Review 1 age'] = df['Date 1'].apply(review_age)\n",
    "df['Review 2 age'] = df['Date 2'].apply(review_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# какой день в году:\n",
    "df['Review 1 day of year'] = df['Date 1'].dt.dayofyear\n",
    "df['Review 2 day of year'] = df['Date 2'].dt.dayofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# длины отзывов (число слов):\n",
    "df['Review 1 length'] = df['Review 1'].apply(lambda x: len(x.split()) if x else None)\n",
    "df['Review 2 length'] = df['Review 2'].apply(lambda x: len(x.split()) if x else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# отзывы:\n",
    "df[['Review 1', 'Review 2']].dropna().stack().value_counts()[47700:]\n",
    "\n",
    "# каждое слово в отдельности:\n",
    "# df[['Review 1', 'Review 2']].dropna().stack().apply(lambda x: x.split()).explode().apply(lambda x: x.lower() if len(x)>2 else None).value_counts()[30:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# оцифровываем отзывы: переведем оценочные суждения в отзывах в систему оценок. Т.к. нлп мы еще не владеем, проведем вручную:\n",
    "impr_dict = {\n",
    "    5: ['excellent', 'delicious', 'great', 'wonderful', 'very good', 'amazing', 'yummy', 'fantastic', 'lovely',\n",
    "       'perfect', 'very nice', 'awesome', 'hidden gem', 'little gem', 'superb', 'brilliant', 'wow', 'loved', 'love', \n",
    "       'recommended', 'outstanding', 'fabulous', 'yum', 'delightful', 'surprise', 'surprised', 'best', 'enjoyable',\n",
    "       'cool', 'really good', 'super', 'what a find', 'unique', 'charming', 'heaven'],\n",
    "    4: ['good', 'not bad', 'nice', 'tasty', 'worth a visit', 'cheerful', 'pretty good', 'friendly', 'fine', \n",
    "        'better than expected', 'cozy', 'reasonable'],\n",
    "    3: ['average', 'ok', 'nothing special', 'overpriced', 'not great', 'expensive', 'overrated', 'hit and miss',\n",
    "       'not impressed', 'not too bad', 'mixed feelings', 'meh ', 'typical', 'standard'],\n",
    "    2: ['disappointing', 'disappointed', 'bad', 'poor', 'below average', 'disappointment', 'rude', 'waste', 'wasting',\n",
    "       'underwhelmed'],\n",
    "    1: ['terrible', 'awful', 'avoid', 'horrible', 'very bad', 'stay away', 'rip off', 'disgusting', 'worst', 'closed']\n",
    "}\n",
    "\n",
    "impr_df = pd.DataFrame(dict([(k,pd.Series(v)) for k, v in impr_dict.items()]))\n",
    "\n",
    "# def get_review_rate(cell):\n",
    "#     for word in impr_df.values:\n",
    "#         print(word, type(word))\n",
    "# #         return ... if word in cell.lower() else None\n",
    "#         if word in cell.lower():\n",
    "#             print(impr_df[impr_df == word].columns)\n",
    "\n",
    "\n",
    "def get_review_rate(cell):\n",
    "    if cell:\n",
    "        for mark in impr_dict:\n",
    "            for word in impr_dict[mark]:\n",
    "                if word in cell.lower():\n",
    "                    return mark\n",
    "\n",
    "\n",
    "df['Review 1 rate'] = df['Review 1'].apply(get_review_rate)\n",
    "df['Review 2 rate'] = df['Review 2'].apply(get_review_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Review 1 length', 'Review 2 length', 'Review 1', 'Review 2']].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordinal parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_ranges = {np.nan: 0, '$': 1, '$$ - $$$': 2, '$$$$': 3}\n",
    "df['Price Range'] = df['Price Range'].apply(lambda x: price_ranges[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Заполнение пропусков в Price Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Restaurant_geo'] == 'Barcelona_Catalonia']['Price Range'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['Restaurant_geo'] == 'Barcelona_Catalonia') & (df['Cuisine Style'] == \"['Mediterranean']\")]['Price Range'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Restaurant_geo'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[df['Restaurant_geo'] == 'Barcelona_Catalonia']['Cuisine Style'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заполнять пропуски в этой колонке нужно осмысленно, значения зависят от разных факторов, например одновременно от города и стиля кухни - видно по разному характеру графиков, когда во внимание берется один или два параметра.\n",
    "\n",
    "Доделаю эту работу похже."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Удаляем текстовые признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v 2.0 for ML\n",
    "# obj_cols = ['Restaurant_id', 'City', 'Cuisine Style', 'Price Range', 'URL_TA', 'ID_TA', 'Review', 'Review date']\n",
    "# obj_cols1 = ['City', 'Cuisine Style', 'Price Range', 'URL_TA', 'ID_TA', 'Review', 'Review date']\n",
    "obj_cols2 = ['City', 'Cuisine Style', 'ID_TA', 'Review 1', 'Review 2', 'Date 1', 'Date 2', 'URL_TA', 'URL_g', 'URL_d', 'Restaurant_title', 'Restaurant_geo']\n",
    "df = df.drop(obj_cols2, axis=1)\n",
    "\n",
    "# values = {col: df[col].mean() for col in \n",
    "#           ['Ranking', 'Rating', 'Number of Reviews', 'Review year', 'Review month', 'Review day']}\n",
    "# values = {col: df[col].mean() for col in \n",
    "#           ['Ranking', 'Rating', 'Number of Reviews', 'Review year', 'Review day of year']}\n",
    "# print(values)\n",
    "df.fillna(df.median(), inplace=True)   # filling in with means\n",
    "\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(df.median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop_duplicates(ignore_index=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v 1.0 for ML\n",
    "# df = pd.read_csv('main_task.csv')\n",
    "\n",
    "# # obj_cols = ['Restaurant_id', 'City', 'Cuisine Style', 'Price Range', 'Reviews', 'URL_TA', 'ID_TA']\n",
    "# obj_cols = ['City', 'Cuisine Style', 'Price Range', 'Reviews', 'URL_TA', 'ID_TA']\n",
    "\n",
    "# df = df.drop(col_drop, axis=1)\n",
    "# # df.fillna(0, inplace=True)\n",
    "\n",
    "# values = {col: df[col].mean() for col in df.columns}\n",
    "# df.fillna(values, inplace=True)\n",
    "\n",
    "# df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Разбиваем датафрейм на части, необходимые для обучения и тестирования модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Х - данные с информацией о ресторанах, у - целевая переменная (рейтинги ресторанов)\n",
    "# X = df.drop(['Restaurant_id', 'Rating'], axis = 1)\n",
    "# X = df.drop(['Rating'], axis = 1)\n",
    "# y = df['Rating']\n",
    "X = df.drop(['Restaurant_id', 'Rating'], axis = 1)\n",
    "y = df['Rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем специальный инструмент для разбивки:\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Наборы данных с меткой \"train\" будут использоваться для обучения модели, \"test\" - для тестирования.\n",
    "# Для тестирования мы будем использовать 25% от исходного датасета.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Создаём, обучаем и тестируем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортируем необходимые библиотеки:\n",
    "from sklearn.ensemble import RandomForestRegressor # инструмент для создания и обучения модели\n",
    "from sklearn import metrics # инструменты для оценки точности модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаём модель\n",
    "regr = RandomForestRegressor(n_estimators=100)\n",
    "\n",
    "# Обучаем модель на тестовом наборе данных\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "# Используем обученную модель для предсказания рейтинга ресторанов в тестовой выборке.\n",
    "# Предсказанные значения записываем в переменную y_pred\n",
    "y_pred = regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сравниваем предсказанные значения (y_pred) с реальными (y_test), и смотрим насколько они в среднем отличаются\n",
    "# Метрика называется Mean Absolute Error (MAE) и показывает среднее отклонение предсказанных значений от фактических.\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Записываем результат для сабмита"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(df.iloc[X_test.index]['Restaurant_id'])\n",
    "result['Rating'] = y_pred\n",
    "result['Rest_id'] = result['Restaurant_id'].apply(lambda x: int(x[3:]))\n",
    "result = result.sort_values('Rest_id')#.drop_duplicates(subset=['Restaurant_id'])\n",
    "result = result.drop('Rest_id', axis=1)\n",
    "result.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_time = datetime.now().strftime('%Y.%m.%d %H-%M')\n",
    "filename = submit_time + ' rds3_Walrave.csv'\n",
    "result.to_csv(path_or_buf=filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
